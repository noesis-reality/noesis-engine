// automatically generated by the FlatBuffers compiler, do not modify

package noesis.protocol

import com.google.flatbuffers.kotlin.*
import kotlin.jvm.JvmInline
@Suppress("unused")
class InferenceResponse : Table() {

    fun init(i: Int, buffer: ReadWriteBuffer) : InferenceResponse = reset(i, buffer)

    val id : String? get() = lookupField(4, null ) { string(it + bufferPos) }
    fun idAsBuffer() : ReadBuffer = vectorAsBuffer(bb, 4, 1)

    val text : String? get() = lookupField(6, null ) { string(it + bufferPos) }
    fun textAsBuffer() : ReadBuffer = vectorAsBuffer(bb, 6, 1)

    fun tokens(j: Int) : UInt = lookupField(8, 0u ) { bb.getUInt(vector(it) + j * 4) }
    val tokensLength : Int get() = lookupField(8, 0 ) { vectorLength(it) }
    fun tokensAsBuffer() : ReadBuffer = vectorAsBuffer(bb, 8, 4)

    val tokensGenerated : UInt get() = lookupField(10, 0u ) { bb.getUInt(it + bufferPos) }

    val timeMs : ULong get() = lookupField(12, 0UL ) { bb.getULong(it + bufferPos) }

    val tokensPerSecond : Double get() = lookupField(14, 0.0 ) { bb.getDouble(it + bufferPos) }

    val gpuMemoryMb : UInt get() = lookupField(16, 0u ) { bb.getUInt(it + bufferPos) }

    val harmonyFormat : String? get() = lookupField(18, null ) { string(it + bufferPos) }
    fun harmonyFormatAsBuffer() : ReadBuffer = vectorAsBuffer(bb, 18, 1)

    fun reasoningSteps(j: Int) : noesis.protocol.ReasoningStep? = reasoningSteps(noesis.protocol.ReasoningStep(), j)
    fun reasoningSteps(obj: noesis.protocol.ReasoningStep, j: Int) : noesis.protocol.ReasoningStep? = lookupField(20, null ) { obj.init(indirect(vector(it) + j * 4), bb) }
    val reasoningStepsLength : Int get() = lookupField(20, 0 ) { vectorLength(it) }

    val error : String? get() = lookupField(22, null ) { string(it + bufferPos) }
    fun errorAsBuffer() : ReadBuffer = vectorAsBuffer(bb, 22, 1)

    companion object {
        fun validateVersion() = VERSION_2_0_8

        fun asRoot(buffer: ReadWriteBuffer) : InferenceResponse = asRoot(buffer, InferenceResponse())
        fun asRoot(buffer: ReadWriteBuffer, obj: InferenceResponse) : InferenceResponse = obj.init(buffer.getInt(buffer.limit) + buffer.limit, buffer)


        fun createInferenceResponse(builder: FlatBufferBuilder, idOffset: Offset<String>, textOffset: Offset<String>, tokensOffset: VectorOffset<UInt>, tokensGenerated: UInt, timeMs: ULong, tokensPerSecond: Double, gpuMemoryMb: UInt, harmonyFormatOffset: Offset<String>, reasoningStepsOffset: VectorOffset<noesis.protocol.ReasoningStep>, errorOffset: Offset<String>) : Offset<InferenceResponse> {
            builder.startTable(10)
            addTokensPerSecond(builder, tokensPerSecond)
            addTimeMs(builder, timeMs)
            addError(builder, errorOffset)
            addReasoningSteps(builder, reasoningStepsOffset)
            addHarmonyFormat(builder, harmonyFormatOffset)
            addGpuMemoryMb(builder, gpuMemoryMb)
            addTokensGenerated(builder, tokensGenerated)
            addTokens(builder, tokensOffset)
            addText(builder, textOffset)
            addId(builder, idOffset)
            return endInferenceResponse(builder)
        }
        fun startInferenceResponse(builder: FlatBufferBuilder) = builder.startTable(10)

        fun addId(builder: FlatBufferBuilder, id: Offset<String>) = builder.add(0, id, 0)

        fun addText(builder: FlatBufferBuilder, text: Offset<String>) = builder.add(1, text, 0)

        fun addTokens(builder: FlatBufferBuilder, tokens: VectorOffset<UInt>) = builder.add(2, tokens, 0)

        fun createTokensVector(builder: FlatBufferBuilder, vector:UIntArray) : VectorOffset<UInt> {
            builder.startVector(4, vector.size, 4)
            for (i in vector.size - 1 downTo 0) {
                builder.add(vector[i])
            }
            return builder.endVector()
        }

        fun startTokensVector(builder: FlatBufferBuilder, numElems: Int) = builder.startVector(4, numElems, 4)

        fun addTokensGenerated(builder: FlatBufferBuilder, tokensGenerated: UInt) = builder.add(3, tokensGenerated, 0u)

        fun addTimeMs(builder: FlatBufferBuilder, timeMs: ULong) = builder.add(4, timeMs, 0UL)

        fun addTokensPerSecond(builder: FlatBufferBuilder, tokensPerSecond: Double) = builder.add(5, tokensPerSecond, 0.0)

        fun addGpuMemoryMb(builder: FlatBufferBuilder, gpuMemoryMb: UInt) = builder.add(6, gpuMemoryMb, 0u)

        fun addHarmonyFormat(builder: FlatBufferBuilder, harmonyFormat: Offset<String>) = builder.add(7, harmonyFormat, 0)

        fun addReasoningSteps(builder: FlatBufferBuilder, reasoningSteps: VectorOffset<noesis.protocol.ReasoningStep>) = builder.add(8, reasoningSteps, 0)

        fun createReasoningStepsVector(builder: FlatBufferBuilder, vector:noesis.protocol.ReasoningStepOffsetArray) : VectorOffset<noesis.protocol.ReasoningStep> {
            builder.startVector(4, vector.size, 4)
            for (i in vector.size - 1 downTo 0) {
                builder.add(vector[i])
            }
            return builder.endVector()
        }

        fun startReasoningStepsVector(builder: FlatBufferBuilder, numElems: Int) = builder.startVector(4, numElems, 4)

        fun addError(builder: FlatBufferBuilder, error: Offset<String>) = builder.add(9, error, 0)

        fun endInferenceResponse(builder: FlatBufferBuilder) : Offset<InferenceResponse> {
            val o: Offset<InferenceResponse> = builder.endTable()
            return o
        }
    }
}

typealias InferenceResponseOffsetArray = OffsetArray<InferenceResponse>

inline fun InferenceResponseOffsetArray(size: Int, crossinline call: (Int) -> Offset<InferenceResponse>): InferenceResponseOffsetArray =
    InferenceResponseOffsetArray(IntArray(size) { call(it).value })
